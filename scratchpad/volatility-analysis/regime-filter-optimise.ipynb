{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Regime filter optimiser\n",
    "\n",
    "- Optimise the regime filter by running a search of different combinations and then testing out it for a different dataset\n",
    "- We use `scikit-optimizer` Python library and its []\n",
    "    - Bayes search is much faster than brute force grid search\n",
    "- We do the search [using multiple parallel workers](https://scikit-optimize.github.io/dev/auto_examples/parallel-optimization.html)\n",
    "    - Some extra setup is needed when transporting data between processes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Set up\n",
    "\n",
    "Set up Trading Strategy data client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:44.624683Z",
     "start_time": "2024-06-12T17:49:44.035269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Trading Strategy in Jupyter notebook environment, configuration is stored in /Users/moo/.tradingstrategy\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "from tradingstrategy.client import Client\n",
    "from tradeexecutor.utils.notebook import setup_charting_and_output, OutputMode\n",
    "\n",
    "client = Client.create_jupyter_client()\n",
    "\n",
    "# Set up drawing charts in interactive vector output mode.\n",
    "# This is slower. See the alternative commented option below.\n",
    "setup_charting_and_output(OutputMode.interactive)\n",
    "\n",
    "# Set up rendering static PNG images.\n",
    "# This is much faster but disables zoom on any chart.\n",
    "#setup_charting_and_output(OutputMode.static, image_format=\"png\", width=1500, height=1000)\n",
    "\n",
    "\n",
    "from tradeexecutor.monkeypatch import cloudpickle_patch  # Enable pickle patch that allows multiprocessing in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Parameters\n",
    "\n",
    "- Strategy parameters define the fixed and grid searched parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:44.984043Z",
     "start_time": "2024-06-12T17:49:44.627002Z"
    }
   },
   "outputs": [],
   "source": [
    "from tradingstrategy.chain import ChainId\n",
    "import datetime\n",
    "\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradeexecutor.strategy.parameters import StrategyParameters\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "\n",
    "    id = \"regime-filter-playground\" # Used in cache paths\n",
    "\n",
    "    candle_time_bucket = TimeBucket.m15  \n",
    "    allocation = 0.98\n",
    "\n",
    "    # See comment below\n",
    "    # adx_length = [i for i in range(7, 60)]\n",
    "    # adx_filter_threshold = [i for i in range(10, 40)]\n",
    "\n",
    "    #\n",
    "    # Backtesting only\n",
    "    #\n",
    "    backtest_start = datetime.datetime(2020, 1, 1)\n",
    "    backtest_end = datetime.datetime(2024, 5, 20)\n",
    "\n",
    "parameters = StrategyParameters.from_class(Parameters)  # Convert to AttributedDict to easier typing with dot notation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search space\n",
    "\n",
    "Because we use scikit we need to define search space using its primitives.\n",
    "We use only discrete integers as a search space, because we cache the calculation results on disk\n",
    "and we do not want to fill the cache with arbitrary floating point values.\n",
    "\n",
    "https://scikit-optimize.github.io/stable/auto_examples/hyperparameter-optimization.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from skopt import space\n",
    "\n",
    "# Because we use scikit-optimizer we need to define\n",
    "# searchable parameters using its search space definition.\n",
    "# The values of these are later passed as argument dict to the optimizer function.\n",
    "search_space = [\n",
    "    space.Integer(7, 60, name=\"adx_length\"),\n",
    "    space.Integer(10, 40, name=\"adx_filter_threshold\")\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:45.539201Z",
     "start_time": "2024-06-12T17:49:44.984339Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trading pairs and market data\n",
    "\n",
    "- Set up our trading pairs\n",
    "- Load historical market data for backtesting\n",
    "- We use Binance CEX data so we have longer history to backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:49.089951Z",
     "start_time": "2024-06-12T17:49:45.539528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading Binance data:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e881350c3fc414d8c270a823ad5fdde"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse\n",
    "from tradingstrategy.client import Client\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext, notebook_execution_context\n",
    "from tradeexecutor.utils.binance import create_binance_universe\n",
    "from tradeexecutor.strategy.universe_model import UniverseOptions\n",
    "\n",
    "trading_pairs = [\n",
    "    (ChainId.centralised_exchange, \"binance\", \"BTC\", \"USDT\"),\n",
    "    (ChainId.centralised_exchange, \"binance\", \"ETH\", \"USDT\"),\n",
    "    (ChainId.centralised_exchange, \"binance\", \"MATIC\", \"USDT\"),\n",
    "    (ChainId.centralised_exchange, \"binance\", \"LINK\", \"USDT\"),\n",
    "    (ChainId.centralised_exchange, \"binance\", \"PEPE\", \"USDT\"),\n",
    "    (ChainId.centralised_exchange, \"binance\", \"BNB\", \"USDT\"),\n",
    "]\n",
    "\n",
    "\n",
    "def create_trading_universe(\n",
    "    timestamp: datetime.datetime,\n",
    "    client: Client,\n",
    "    execution_context: ExecutionContext,\n",
    "    universe_options: UniverseOptions,\n",
    ") -> TradingStrategyUniverse:\n",
    "    strategy_universe = create_binance_universe(\n",
    "        [f\"{p[2]}{p[3]}\" for p in trading_pairs],\n",
    "        candle_time_bucket=Parameters.candle_time_bucket,\n",
    "        start_at=universe_options.start_at,\n",
    "        end_at=universe_options.end_at,\n",
    "        forward_fill=True,\n",
    "    )\n",
    "    return strategy_universe\n",
    "\n",
    "\n",
    "strategy_universe = create_trading_universe(\n",
    "    None,\n",
    "    client,\n",
    "    notebook_execution_context,\n",
    "    UniverseOptions.from_strategy_parameters_class(Parameters, notebook_execution_context)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Indicators\n",
    "\n",
    "- We use `pandas_ta` Python package to calculate technical indicators\n",
    "- These indicators are precalculated and cached on the disk\n",
    "- Indicators are calculated to each pair in our trading pair dataset\n",
    "- Indicators depend on each other based on [indicator dependency order resolution](https://tradingstrategy.ai/docs/api/execution/help/tradeexecutor.strategy.pandas_trader.indicator.IndicatorDependencyResolver.html#indicatordependencyresolver)\n",
    "- We need to define the dependency order resolution, because indicators are calculater in parallel, using multiple CPUs, for the max speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from tradeexecutor.state.identifier import TradingPairIdentifier\n",
    "import pandas as pd\n",
    "import pandas_ta\n",
    "\n",
    "from tradeexecutor.analysis.regime import Regime\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import IndicatorSet, IndicatorSource, IndicatorDependencyResolver\n",
    "from tradeexecutor.strategy.parameters import StrategyParameters\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse\n",
    "from tradingstrategy.utils.groupeduniverse import resample_candles\n",
    "\n",
    "\n",
    "def daily_price(open, high, low, close) -> pd.DataFrame:\n",
    "    \"\"\"Resample finer granularity price feed to daily for ADX filtering.\"\"\"\n",
    "    original_df = pd.DataFrame({\n",
    "        \"open\": open,\n",
    "        \"high\": high,\n",
    "        \"low\": low,\n",
    "        \"close\": close,\n",
    "    })    \n",
    "    daily_df = resample_candles(original_df, pd.Timedelta(days=1))\n",
    "    return daily_df\n",
    "\n",
    "\n",
    "def daily_adx(\n",
    "    open,\n",
    "    high,\n",
    "    low,\n",
    "    close,\n",
    "    length,\n",
    "    pair: TradingPairIdentifier,\n",
    "    dependency_resolver: IndicatorDependencyResolver,\n",
    "):\n",
    "    \"\"\"Calculate ADX indicator based on daily prices.\n",
    "\n",
    "    - ADX https://www.investopedia.com/articles/trading/07/adx-trend-indicator.asp\n",
    "    - https://github.com/twopirllc/pandas-ta/blob/main/pandas_ta/trend/adx.py\n",
    "    \"\"\"\n",
    "    daily_df = dependency_resolver.get_indicator_data(\n",
    "        \"daily_price\",\n",
    "        pair=pair,\n",
    "        column=\"all\",\n",
    "    )\n",
    "    adx_df = pandas_ta.adx(\n",
    "        close=daily_df.close,\n",
    "        high=daily_df.high,\n",
    "        low=daily_df.low,\n",
    "        length=length,\n",
    "    )\n",
    "    return adx_df\n",
    "\n",
    "\n",
    "def regime(\n",
    "    close: pd.Series,\n",
    "    adx_length: int,\n",
    "    regime_threshold: float,\n",
    "    pair: TradingPairIdentifier,\n",
    "    dependency_resolver: IndicatorDependencyResolver,\n",
    ") -> pd.Series:\n",
    "    \"\"\"A regime filter based on ADX indicator.\n",
    "\n",
    "    Get the trend of BTC applying ADX on a daily frame.\n",
    "    \n",
    "    - -1 is bear\n",
    "    - 0 is sideways\n",
    "    - +1 is bull\n",
    "    \"\"\"\n",
    "    adx_df = dependency_resolver.get_indicator_data(\n",
    "        \"adx\",\n",
    "        pair=pair,\n",
    "        parameters={\"length\": adx_length},\n",
    "        column=\"all\",\n",
    "    )\n",
    "\n",
    "    def regime_filter(row):\n",
    "        # ADX, DMP, # DMN\n",
    "        average_direction_index, directional_momentum_positive, directional_momentum_negative = row.values\n",
    "        if average_direction_index > regime_threshold:\n",
    "            if directional_momentum_positive > directional_momentum_negative:\n",
    "                return Regime.bull.value\n",
    "            else:\n",
    "                return Regime.bear.value\n",
    "        else:\n",
    "            return Regime.crab.value\n",
    "\n",
    "    regime_signal = adx_df.apply(regime_filter, axis=\"columns\")    \n",
    "    return regime_signal\n",
    "\n",
    "\n",
    "def create_indicators(\n",
    "    timestamp: datetime.datetime | None,\n",
    "    parameters: StrategyParameters,\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    "    execution_context: ExecutionContext\n",
    "):\n",
    "    indicators = IndicatorSet()\n",
    "\n",
    "    indicators.add(\n",
    "        \"daily_price\",\n",
    "        daily_price,\n",
    "        {},\n",
    "        IndicatorSource.ohlcv,\n",
    "        order=1,\n",
    "    )\n",
    "\n",
    "    indicators.add(\n",
    "        \"adx\",\n",
    "        daily_adx,\n",
    "        {\"length\": parameters.adx_length},\n",
    "        IndicatorSource.ohlcv,\n",
    "        order=2,\n",
    "    )\n",
    "\n",
    "    # A regime filter to detect the trading pair bear/bull markets\n",
    "    indicators.add(\n",
    "        \"regime\",\n",
    "        regime,\n",
    "        {\"adx_length\": parameters.adx_length, \"regime_threshold\": parameters.adx_filter_threshold},\n",
    "        IndicatorSource.close_price,\n",
    "        order=3.\n",
    "    )\n",
    "        \n",
    "    return indicators\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:49.167417Z",
     "start_time": "2024-06-12T17:49:49.094877Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regime filter accuracy test\n",
    "\n",
    "- We define the accuracy of the regime filter by how many bull market days we matched\n",
    "  during the bull region\n",
    "- Bull market only, because we trade long only breakouts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# If the market moves +/- 1% a day we consider the move significant to trade\n",
    "# Roughly assuming: 30 BPS in and out fees = 60 BPS\n",
    "significant_move = 0.01\n",
    "\n",
    "def calculate_regime_filter_accuracy_df(\n",
    "    close: pd.Series,\n",
    "    regime_filter: pd.Series,\n",
    "    bull_threshold = significant_move,\n",
    "    bear_threshold = significant_move,\n",
    "):\n",
    "    \"\"\"Calcualte dataframe with accuracy detection for regime filter.\n",
    "\n",
    "    - Flag how money bullish/bearish days we detected correctly\n",
    "\n",
    "    :param close:\n",
    "        Daily close series\n",
    "\n",
    "    :param regime_filter:\n",
    "        Regime filter series\n",
    "\n",
    "    :param bull_threshold:\n",
    "        Daily price increase to mark a day as bull market day\n",
    "\n",
    "    :param bearish_threshold:\n",
    "        Daily price decrease to mark a da as a bear day\n",
    "\n",
    "    :return:\n",
    "        Dataframe with column flags for true bull/bear days and if we had a match\n",
    "    \"\"\"\n",
    "    backwards_shifted_close = close.shift(-1)\n",
    "    diff = (close - backwards_shifted_close) / backwards_shifted_close  # Intra day price diff or \"daily returns\"\n",
    "    bullish_days = diff > bull_threshold\n",
    "    bearish_days = diff < bear_threshold\n",
    "    bullish_match = bullish_days & regime_filter[regime_filter == Regime.bull.value]  # +1\n",
    "    bearish_match = bearish_days & regime_filter[regime_filter == Regime.bear.value]  # -1\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"close\": close,\n",
    "        \"backwards_shifted_close\": backwards_shifted_close,\n",
    "        \"diff\": diff,\n",
    "        \"regime_filter\": regime_filter,\n",
    "        \"bullish_days\": bullish_days,\n",
    "        \"bearish_days\": bearish_days,\n",
    "        \"bullish_match\": bullish_match,\n",
    "        \"bearish_match\": bearish_match,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_regime_match_statistics(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Calculate statsitics how well the regime filter worked.\"\"\"\n",
    "    total = len(df)\n",
    "    bullish_match_count = (df.bullish_match == True).sum() / total\n",
    "    bearish_match_count = (df.bearish_match == True).sum() / total\n",
    "    return pd.Series({\n",
    "        \"bullish_hits\": (df.bullish_match == True).sum(),\n",
    "        \"bearish_hits\": (df.bullish_match == True).sum(),\n",
    "        \"bullish_success\": bullish_match_count,\n",
    "        \"bearish_success\": bearish_match_count,\n",
    "        \"total\": total,\n",
    "    })\n",
    "\n",
    "\n",
    "def evalute_regime_filter_accuracy(\n",
    "        strategy_universe: TradingStrategyUniverse,\n",
    "        indicator_results: IndicatorSet\n",
    ") -> float:\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for pair_desc in trading_pairs:\n",
    "        pair = strategy_universe.get_pair_by_human_description(pair_desc)\n",
    "\n",
    "        # Pull the pair and its close price we are detecting regimes for\n",
    "        daily_price = indicator_results.get_indicator_dataframe(\"daily_price\", pair=pair)\n",
    "        close = daily_price[\"close\"]\n",
    "        regime_filter = indicator_results.get_indicator_series(\"regime\", pair=trading_pairs[0], unlimited=True)\n",
    "\n",
    "        df = calculate_regime_filter_accuracy_df(\n",
    "            close,\n",
    "            regime_filter,\n",
    "        )\n",
    "        #display(df)\n",
    "        summary_row = calculate_regime_match_statistics(df)\n",
    "        data[pair.get_ticker()] = summary_row\n",
    "\n",
    "    print(\"Regime filter match results\")\n",
    "    #summary_df = pd.DataFrame(data).T  # Transpose\n",
    "    #display(summary_df)\n",
    "\n",
    "    return summary_df[\"bullish_success\"].avg()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:49.173273Z",
     "start_time": "2024-06-12T17:49:49.171356Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the optimisatio function\n",
    "\n",
    "- Set up the regime filter indicator search so that it is available as an optimise function for scikit-optimize\n",
    "- We have some extra ceremony around passing the strategy universe over multiprocessing boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:49.957861Z",
     "start_time": "2024-06-12T17:49:49.176118Z"
    }
   },
   "outputs": [],
   "source": [
    "from skopt.utils import use_named_args\n",
    "\n",
    "from tradeexecutor.strategy.execution_context import scikit_optimizer_context\n",
    "from tradeexecutor.strategy.pandas_trader.strategy_input import StrategyInputIndicators\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import calculate_and_load_indicators, DiskIndicatorStorage\n",
    "from tradeexecutor.backtest.grid_search import \\\n",
    "    load_multiprocess_strategy_universe, initialise_multiprocess_strategy_universe_from_disk\n",
    "\n",
    "\n",
    "# Type hinting to help with the code readability,\n",
    "# same as scikit-optimizer generates from search_parameters above\n",
    "class SearchParams(typing.TypedDict):\n",
    "    adx_length: float\n",
    "    adx_filter: float\n",
    "\n",
    "\n",
    "def run_indicator_search(\n",
    "    **search_params: SearchParams,\n",
    ") -> float:\n",
    "    \"\"\"Run one indicator fit iteration.\n",
    "\n",
    "    - Calculate indicators (and save results for caching)\n",
    "\n",
    "    - Check how well these indicator parameters fit to our goal (regime filter accuracy)\n",
    "\n",
    "    :param strategy_universe:\n",
    "        The current strategy universe\n",
    "\n",
    "    :return:\n",
    "        The optimised parameter result\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the strategy universe data\n",
    "    # given to the worker process when the parent process forked\n",
    "    strategy_universe = load_multiprocess_strategy_universe()\n",
    "\n",
    "    # Indicator values should be immutable for each strategy universe,\n",
    "    # so we get cache indicator results, as per parameters, for each\n",
    "    # universe (trading pair + time window combo) in a separate folder\n",
    "    indicator_storage = DiskIndicatorStorage.create_default(strategy_universe)\n",
    "\n",
    "    # Take the parameters of this iteration and convert them\n",
    "    # to trade-executor internal format.\n",
    "    # Convert the scikit-optimize search space values\n",
    "    # to our keyed indicator values, so we can cache the result.\n",
    "    strategy_params = StrategyParameters.from_dict(search_params)\n",
    "    indicator_set = create_indicators(\n",
    "        None,\n",
    "        strategy_params,\n",
    "        strategy_universe,\n",
    "        execution_context=scikit_optimizer_context,\n",
    "    )\n",
    "\n",
    "    # Calculate, save or load cached values for our indicators.\n",
    "    # In the case there is a race condition, cache files are written\n",
    "    # atomically and the latest write wins.\n",
    "    indicator_result_map = calculate_and_load_indicators(\n",
    "        strategy_universe=strategy_universe,\n",
    "        storage=indicator_storage,\n",
    "        parameters=parameters,\n",
    "        execution_context=notebook_execution_context,\n",
    "        indicators=indicator_set,\n",
    "        max_workers=1,\n",
    "    )\n",
    "\n",
    "    # Create the same API helper as we use to access the\n",
    "    # indicator data in decide_trades() of the tarding strategy\n",
    "    indicator_results = StrategyInputIndicators(\n",
    "        strategy_universe,\n",
    "        available_indicators=indicator_set,\n",
    "        indicator_results=indicator_result_map,\n",
    "    )\n",
    "\n",
    "    # Check how accurate regime filter would be with these indicator parameters\n",
    "    accuracy = evalute_regime_filter_accuracy(\n",
    "        strategy_universe,\n",
    "        indicator_results\n",
    "    )\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "@use_named_args(search_space)\n",
    "def objective_unpacked(**params) -> float:\n",
    "    \"\"\"Scikit-optimizer objective function.\n",
    "\n",
    "    - In our case this function is called in its own child process\n",
    "\n",
    "    :return:\n",
    "        A single floating point value telling how good we did.\n",
    "\n",
    "        Higher is better.\n",
    "    \"\"\"\n",
    "    return run_indicator_search(**params)\n",
    "\n",
    "\n",
    "def objective(pickled_universe_fname: str, args: list):\n",
    "    # Pass the strategy universe immutable to the child process\n",
    "    initialise_multiprocess_strategy_universe_from_disk(pickled_universe_fname)\n",
    "    # Run the optimizer function with the loaded strategy universe\n",
    "    return objective_unpacked(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimise\n",
    "\n",
    "- Internally scikit-optimize [uses Joblib for the parallel execution](https://joblib.readthedocs.io/en/latest/parallel.html)\n",
    "- Run the Bayes search over the optimizer function\n",
    "- [See the original parallel processing example for scikit-optimize](https://scikit-optimize.github.io/dev/auto_examples/parallel-optimization.html\n",
    "\n",
    "Summary of what's happening here, by Claude:\n",
    "\n",
    "Imagine you are trying to find the highest point on a mountain, but you can't see the entire mountain at once. You can only see a small area around you. To find the highest point, you would need to explore different areas of the mountain and keep track of the heights you've observed so far.\n",
    "\n",
    "In this analogy, the mountain represents the objective function (the thing you're trying to optimize), and the small areas you can see represent the points you've evaluated so far.\n",
    "\n",
    "Now, let's bring in Gaussian Processes (GPs). A GP is like a smart friend who can look at the heights you've observed so far and make educated guesses about what the mountain might look like in other areas. Based on the points you've explored, your GP friend can create a map of the mountain, showing the most likely heights at different locations.\n",
    "\n",
    "The map created by your GP friend is not perfect, but it's a reasonable approximation based on the information available. The GP also gives you an idea of how confident it is about its guesses. Areas where you've explored a lot will have higher confidence, while unexplored areas will have lower confidence.\n",
    "\n",
    "This is where Bayesian methods come into play. Bayesian methods are like a way of updating your GP friend's map as you explore more areas of the mountain.\n",
    "\n",
    "Initially, your GP friend has a prior belief about what the mountain might look like based on some general knowledge. This is like a rough sketch of the mountain.\n",
    "\n",
    "As you explore new areas and observe new heights, your GP friend uses Bayesian methods to update their map (their belief) about the shape of the mountain. The new observations (the heights you've measured) are combined with their prior belief to create a new, more accurate map (a posterior belief).\n",
    "\n",
    "The process of exploring new areas, observing heights, and updating the GP's map (belief) using Bayesian methods continues until you're confident you've found the highest point on the mountain (the global optimum of the objective function).\n",
    "\n",
    "In scikit-optimize, this iterative process of exploring the objective function, updating the GP model (the belief) using Bayesian methods, and selecting the next point to explore based on the updated GP model is called Bayesian Optimization.\n",
    "\n",
    "The key scientific terms in this explanation are:\n",
    "\n",
    "1. Objective function: The thing you're trying to optimize (find the highest/lowest value of), represented by the mountain in the analogy.\n",
    "2. Gaussian Process (GP): A smart friend who can make educated guesses about the shape of the mountain based on the points you've explored so far.\n",
    "3. Prior belief: The GP's initial guess about the shape of the mountain before any observations are made.\n",
    "4. Bayesian methods: A way of updating the GP's belief (map) about the shape of the mountain as new observations (heights) are made.\n",
    "5. Posterior belief: The GP's updated belief (map) about the shape of the mountain after incorporating new observations using Bayesian methods.\n",
    "6. Bayesian Optimization: The iterative process of exploring the objective function, updating the GP model using Bayesian methods, and selecting the next point to explore based on the updated GP model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /var/folders/tx/50wn88yd40v2_6_7fvfr98z00000gn/T/tmpho197hj8/centralised-exchange_15m_6_2020-01-01-2024-05-20_ff.pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": "Searching the best parameters for the regime filtering:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e67ac2e7492482d8a0b3df5f26e8138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'summary_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/moo/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/Users/moo/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/moo/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/moo/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/moo/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n    return self.function(*args, **kwargs)\n  File \"/var/folders/tx/50wn88yd40v2_6_7fvfr98z00000gn/T/ipykernel_1752/2721812179.py\", line 100, in objective\n  File \"/Users/moo/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/skopt/utils.py\", line 779, in wrapper\n    objective_value = func(**arg_dict)\n  File \"/var/folders/tx/50wn88yd40v2_6_7fvfr98z00000gn/T/ipykernel_1752/2721812179.py\", line 93, in objective_unpacked\n  File \"/var/folders/tx/50wn88yd40v2_6_7fvfr98z00000gn/T/ipykernel_1752/2721812179.py\", line 75, in run_indicator_search\n  File \"/var/folders/tx/50wn88yd40v2_6_7fvfr98z00000gn/T/ipykernel_1752/2269164516.py\", line 91, in evalute_regime_filter_accuracy\nNameError: name 'summary_df' is not defined. Did you mean: 'summary_row'?\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 36\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, iterations):\n\u001B[1;32m     35\u001B[0m     x \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mask(n_points\u001B[38;5;241m=\u001B[39mbatch_size)  \u001B[38;5;66;03m# x is a list of n_points points\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mworker_processor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43msaved_universe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# evaluate points in parallel\u001B[39;00m\n\u001B[1;32m     37\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mtell(x, y)\n\u001B[1;32m     39\u001B[0m     progress_bar\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest result\u001B[39m\u001B[38;5;124m\"\u001B[39m: optimizer\u001B[38;5;241m.\u001B[39myi})\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     66\u001B[0m )\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[1;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[1;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[1;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[0;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[1;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[1;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[1;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py:1754\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_retrieval():\n\u001B[1;32m   1748\u001B[0m \n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[1;32m   1751\u001B[0m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[1;32m   1752\u001B[0m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborting:\n\u001B[0;32m-> 1754\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1755\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m   1757\u001B[0m     \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m     \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py:1789\u001B[0m, in \u001B[0;36mParallel._raise_error_fast\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1785\u001B[0m \u001B[38;5;66;03m# If this error job exists, immediately raise the error by\u001B[39;00m\n\u001B[1;32m   1786\u001B[0m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[1;32m   1787\u001B[0m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[1;32m   1788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1789\u001B[0m     \u001B[43merror_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py:745\u001B[0m, in \u001B[0;36mBatchCompletionCallBack.get_result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    739\u001B[0m backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparallel\u001B[38;5;241m.\u001B[39m_backend\n\u001B[1;32m    741\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39msupports_retrieve_callback:\n\u001B[1;32m    742\u001B[0m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[1;32m    743\u001B[0m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[1;32m    744\u001B[0m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[0;32m--> 745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[1;32m    748\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/trade-executor-0IMGzMxl-py3.10/lib/python3.10/site-packages/joblib/parallel.py:763\u001B[0m, in \u001B[0;36mBatchCompletionCallBack._return_or_raise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    762\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m TASK_ERROR:\n\u001B[0;32m--> 763\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[1;32m    764\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n\u001B[1;32m    765\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'summary_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.parallel import Parallel, delayed\n",
    "from skopt import Optimizer\n",
    "\n",
    "from tqdm_loggable.auto import tqdm\n",
    "\n",
    "from tradeexecutor.utils.cpu import get_safe_max_workers_count\n",
    "from tradeexecutor.backtest.grid_search import save_disk_multiprocess_strategy_universe\n",
    "\n",
    "# How many search iterations we run\n",
    "iterations = 10\n",
    "\n",
    "# How many points go over once\n",
    "batch_size = 4\n",
    "\n",
    "# Allocate all CPUs minus some needed for UI rendering\n",
    "parallel_jobs = get_safe_max_workers_count()\n",
    "\n",
    "# Set up scikit-optimizer for Gaussian Process (Bayes)\n",
    "optimizer = Optimizer(\n",
    "    dimensions=search_space,\n",
    "    random_state=1,\n",
    "    base_estimator='gp'  # gp stands for Gaussian Process\n",
    ")\n",
    "\n",
    "# Set up a joblib processor using multiprocessing (forking)\n",
    "worker_processor = Parallel(\n",
    "    n_jobs=parallel_jobs,\n",
    "    backend=\"loky\",\n",
    ")\n",
    "\n",
    "saved_universe = save_disk_multiprocess_strategy_universe(strategy_universe)\n",
    "\n",
    "with tqdm(total=iterations, desc=\"Searching the best parameters for the regime filtering\") as progress_bar:\n",
    "    for i in range(0, iterations):\n",
    "        x = optimizer.ask(n_points=batch_size)  # x is a list of n_points points\n",
    "        y = worker_processor(delayed(objective)(saved_universe, v) for v in x)  # evaluate points in parallel\n",
    "        optimizer.tell(x, y)\n",
    "\n",
    "        progress_bar.set_postfix({\"Best result\": optimizer.yi})\n",
    "        progress_bar.update()\n",
    "\n",
    "print(\"The best score was\", optimizer.yi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:49:53.996656Z",
     "start_time": "2024-06-12T17:49:49.959877Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market regime indicator visualisation\n",
    "\n",
    "- In this example we use ADX values as the market regime filter\n",
    "- For a strategy, the regime filter can be calculated per-pair or by an index - BTC price is a popular index for all cryptocurrency markets\n",
    "- Visualise the regime filter to show how well our bear/bull market flagging works\n",
    "- Render a chart for each trading pair in our trading universe\n",
    "\n",
    "First we lay out the regime filter signal on the top of price chart.\n",
    "\n",
    "- Green: bull market regime detected\n",
    "- Red: bear market regime detected\n",
    "- No background colour: sideways (crab) market detected\n",
    "\n",
    "Then we display raw ADX indicator values for the trading pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.visual.bullbear import visualise_market_regime_filter\n",
    "from tradeexecutor.visual.bullbear import visualise_raw_market_regime_indicator\n",
    "\n",
    "for pair_desc in trading_pairs:\n",
    "    pair = strategy_universe.get_pair_by_human_description(pair_desc)\n",
    "\n",
    "    # Pull the pair and its close price we are detecting regimes for\n",
    "    daily_price = indicator_results.get_indicator_dataframe(\"daily_price\", pair=pair)\n",
    "    close_price = daily_price[\"close\"]\n",
    "\n",
    "    regime_signal = indicator_results.get_indicator_series(\"regime\", pair=trading_pairs[0], unlimited=True)\n",
    "    figure = visualise_market_regime_filter(\n",
    "        close_price,\n",
    "        regime_signal,\n",
    "        title=f\"{pair.base.token_symbol} regime filter\"\n",
    "    )\n",
    "    figure.show()\n",
    "\n",
    "    adx_df = indicator_results.get_indicator_dataframe(\"adx\", pair=pair)\n",
    "    figure = visualise_raw_market_regime_indicator(\n",
    "        close_price,\n",
    "        adx_df,\n",
    "        height=500,\n",
    "        indicator_height=150,\n",
    "        title=f\"{pair.base.token_symbol} market regime indicator data\"\n",
    "    )\n",
    "    figure.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regime filter summary\n",
    "\n",
    "- We d\n",
    "- The bullish/bearish success metric is not absolute, but ranking one: Higher is better, but the number itself is meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the market moves +/- 1% a day we consider the move significant to trade\n",
    "# Roughly assuming: 30 BPS in and out fees = 60 BPS\n",
    "significant_move = 0.01\n",
    "\n",
    "def calculate_regime_filter_accuracy_df(\n",
    "    close: pd.Series,\n",
    "    regime_filter: pd.Series,\n",
    "    bull_threshold = significant_move,\n",
    "    bear_threshold = significant_move,\n",
    "):\n",
    "    \"\"\"Calcualte dataframe with accuracy detection for regime filter.\n",
    "    \n",
    "    - Flag how money bullish/bearish days we detected correctly\n",
    "\n",
    "    :param close:\n",
    "        Daily close series\n",
    "\n",
    "    :param regime_filter:\n",
    "        Regime filter series\n",
    "\n",
    "    :param bull_threshold:\n",
    "        Daily price increase to mark a day as bull market day\n",
    "\n",
    "    :param bearish_threshold:\n",
    "        Daily price decrease to mark a da as a bear day\n",
    "\n",
    "    :return:    \n",
    "        Dataframe with column flags for true bull/bear days and if we had a match\n",
    "    \"\"\"\n",
    "    backwards_shifted_close = close.shift(-1)\n",
    "    diff = (close - backwards_shifted_close) / backwards_shifted_close  # Intra day price diff or \"daily returns\"\n",
    "    bullish_days = diff > bull_threshold\n",
    "    bearish_days = diff < bear_threshold\n",
    "    bullish_match = bullish_days & regime_filter[regime_filter == Regime.bull.value]  # +1\n",
    "    bearish_match = bearish_days & regime_filter[regime_filter == Regime.bear.value]  # -1\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"close\": close,\n",
    "        \"backwards_shifted_close\": backwards_shifted_close,\n",
    "        \"diff\": diff,\n",
    "        \"regime_filter\": regime_filter,        \n",
    "        \"bullish_days\": bullish_days,\n",
    "        \"bearish_days\": bearish_days,\n",
    "        \"bullish_match\": bullish_match,\n",
    "        \"bearish_match\": bearish_match,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_regime_match_statistics(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Calculate statsitics how well the regime filter worked.\"\"\"\n",
    "    total = len(df)\n",
    "    bullish_match_count = (df.bullish_match == True).sum() / total\n",
    "    bearish_match_count = (df.bearish_match == True).sum() / total\n",
    "    return pd.Series({\n",
    "        \"bullish_hits\": (df.bullish_match == True).sum(),\n",
    "        \"bearish_hits\": (df.bullish_match == True).sum(),\n",
    "        \"bullish_success\": bullish_match_count,\n",
    "        \"bearish_success\": bearish_match_count,\n",
    "        \"total\": total,\n",
    "    })\n",
    "\n",
    "\n",
    "data = {}\n",
    "\n",
    "for pair_desc in trading_pairs:\n",
    "    pair = strategy_universe.get_pair_by_human_description(pair_desc)\n",
    "\n",
    "    # Pull the pair and its close price we are detecting regimes for\n",
    "    daily_price = indicator_results.get_indicator_dataframe(\"daily_price\", pair=pair)\n",
    "    close = daily_price[\"close\"]\n",
    "    regime_filter = indicator_results.get_indicator_series(\"regime\", pair=trading_pairs[0], unlimited=True)\n",
    "\n",
    "    df = calculate_regime_filter_accuracy_df(\n",
    "        close,\n",
    "        regime_filter,        \n",
    "    )\n",
    "    display(df)\n",
    "    summary_row = calculate_regime_match_statistics(df)\n",
    "    data[pair.get_ticker()] = summary_row\n",
    "    \n",
    "print(\"Regime filter match results\")\n",
    "summary_df = pd.DataFrame(data).T  # Transpose\n",
    "display(summary_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
