{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Liquidity risk example\n",
    "\n",
    "An example strategy backtest against available liquidity data.\n",
    "\n",
    "- Based on `portfolio-construction` and `alternative-data` examples\n",
    "    - Trades using portfolio construction and alpha model\n",
    "- Run a [portfolio construction strategy](https://tradingstrategy.ai/blog/writing-portfolio-construction-strategy-in-python) based on the signal\n",
    "    - In a real strategy this signal needs to be combined with other signals.\n",
    "- Checks that a trading pair exceeds a liquidity threshold so it can be traded,\n",
    "  based on the available historical liquidity at the point of time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "To run this backtest, you first need to run `scripts/prefilter-polygon.py` to build a Polygon dataset (> 1 GB) for this backtest based on more than 10 GB downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# See scripts/prefilter-polygon.py\n",
    "liquidity_output_fname = Path(\"/tmp/polygon-liquidity-prefiltered.parquet\")\n",
    "price_output_fname = Path(\"/tmp/polygon-price-prefiltered.parquet\")\n",
    "\n",
    "assert price_output_fname.exists(), \"Run prefilter script first\"\n",
    "assert liquidity_output_fname.exists(), \"Run prefilter script first\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Set up\n",
    "\n",
    "Set up Trading Strategy data client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-10T10:44:22.771956Z"
    }
   },
   "outputs": [],
   "source": [
    "from tradeexecutor.utils.notebook import setup_charting_and_output\n",
    "from tradingstrategy.client import Client\n",
    "from tradeexecutor.utils.notebook import setup_charting_and_output, OutputMode\n",
    "\n",
    "client = Client.create_jupyter_client()\n",
    "\n",
    "# Set up drawing charts in interactive vector output mode.\n",
    "# This is slower. See the alternative commented option below.\n",
    "# Kernel restart needed if you change output mode.\n",
    "# setup_charting_and_output(OutputMode.interactive)\n",
    "\n",
    "# Set up rendering static PNG images.\n",
    "# This is much faster but disables zoom on any chart.\n",
    "setup_charting_and_output(OutputMode.static, image_format=\"png\", width=1500, height=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Parameters\n",
    "\n",
    "- Strategy parameters define the fixed and grid searched parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-10T10:44:22.772613Z"
    }
   },
   "outputs": [],
   "source": [
    "from tradingstrategy.chain import ChainId\n",
    "import datetime\n",
    "\n",
    "from tradeexecutor.strategy.default_routing_options import TradeRouting\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradeexecutor.strategy.cycle import CycleDuration\n",
    "from tradeexecutor.strategy.parameters import StrategyParameters\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "    \"\"\"Parameteres for this strategy.\n",
    "\n",
    "    - Collect parameters used for this strategy here\n",
    "\n",
    "    - Both live trading and backtesting parameters\n",
    "    \"\"\"\n",
    "\n",
    "    id = \"portfolio-construction\" # Used in cache paths\n",
    "\n",
    "    cycle_duration = CycleDuration.d1  # Daily rebalance\n",
    "    candle_time_bucket = TimeBucket.d1  \n",
    "    allocation = 0.98   \n",
    "    \n",
    "    max_assets = 4  # How many assets hold in portfolio once\n",
    "    rsi_length = 7   # Use 7 days RSI as the alpha signal for a trading pair\n",
    "    minimum_rebalance_trade_percent = 0.25  # Portfolio must change at least 1/4 before we start doing rebalance trades\n",
    "\n",
    "    #\n",
    "    # Filtering and data quality\n",
    "    #\n",
    "    min_liquidity = 100_000  # Do not trade pairs below this amount of USD locked in TVL\n",
    "    min_price = 0.000001  # Filter out trading pairs with bad price units\n",
    "    max_price = 1_000_000  # Filter out trading pairs with bad price units\n",
    "\n",
    "    #\n",
    "    # Live trading only\n",
    "    #\n",
    "    chain_id = ChainId.polygon\n",
    "    routing = TradeRouting.default  # Pick default routes for trade execution\n",
    "    required_history_period = datetime.timedelta(days=rsi_length + 1)\n",
    "\n",
    "    #\n",
    "    # Backtesting only\n",
    "    #\n",
    "    backtest_start = datetime.datetime(2023, 1, 1)\n",
    "    backtest_end = datetime.datetime(2024, 1, 1)\n",
    "    initial_cash = 10_000\n",
    "    stop_loss_time_bucket = TimeBucket.h1  # Must match scripts/prefilter-polygon.py\n",
    "\n",
    "\n",
    "parameters = StrategyParameters.from_class(Parameters)  # Convert to AttributedDict to easier typing with dot notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the custom data from a CSV file.\n",
    "\n",
    "- Load using Pandas\n",
    "- This data will be split and mapped to per-pair indicators later on, as the data format is per-pair\n",
    "\n",
    "*Note*: Relative paths work different in different notebook run-time environments. Below is for Visual Studio Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "CSV_PATH = os.environ.get(\"CSV_PATH\", \"../../data/df_trend_polygon.csv\")  # Allow override location for command line ipython\n",
    "\n",
    "custom_data_df = pd.read_csv(CSV_PATH)  # For the repo, we keep a partial sample of the data\n",
    "custom_data_df.index = pd.DatetimeIndex(custom_data_df[\"date\"])\n",
    "custom_data_df[\"contract_address\"] = custom_data_df[\"contract_address\"].str.lower()  # Framework operates with lowercased addresses everywehre\n",
    "\n",
    "start = custom_data_df.index[0]\n",
    "end = custom_data_df.index[-1]\n",
    "\n",
    "csv_token_list = list(custom_data_df.contract_address.unique())\n",
    "print(f\"CSV contains data for {len(csv_token_list)} tokens, time range {start} - {end}\")\n",
    "\n",
    "# Create per-pair DataFrame group by\n",
    "custom_data_group = custom_data_df.groupby(\"contract_address\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trading pairs and market data\n",
    "\n",
    "- Read preprocessed price OHLCV and liquidity dataframes in memory\n",
    "- Get a list of ERC-20 tokens we are going to trade on Polygon\n",
    "- Create an union where we have 1) our tokens from CSV and then 2) trading pairs with polygon data\n",
    "- Apply filter prefiltering from `Parameters.min_liquidity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tradingstrategy.universe import Universe\n",
    "from tradingstrategy.liquidity import GroupedLiquidityUniverse\n",
    "from tradeexecutor.strategy.pandas_trader.alternative_market_data import resample_multi_pair\n",
    "from tradingstrategy.candle import GroupedCandleUniverse\n",
    "from tradingstrategy.pair import filter_for_base_tokens, PandasPairUniverse, StablecoinFilteringMode, \\\n",
    "    filter_for_stablecoins\n",
    "from tradingstrategy.client import Client\n",
    "\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse, translate_token\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext, notebook_execution_context\n",
    "from tradeexecutor.strategy.universe_model import UniverseOptions\n",
    "\n",
    "WMATIC = \"0x0d500b1d8e8ef31e21c99d1db9a6444d3adf1270\"\n",
    "USDCE = \"0x2791bca1f2de4661ed88a30c99a7a9449aa84174\"\n",
    "\n",
    "# We care only Quickswap and Uniswap v3 pairs\n",
    "SUPPORTED_DEXES = {\n",
    "    \"quickswap\",\n",
    "    \"uniswap-v3\"\n",
    "}\n",
    "\n",
    "# Get the token list of everything in the CSV + hardcoded WMATIC\n",
    "custom_data_token_set = {WMATIC} | set(csv_token_list)\n",
    "\n",
    "def create_trading_universe(\n",
    "    timestamp: datetime.datetime | None,\n",
    "    client: Client,\n",
    "    execution_context: ExecutionContext,\n",
    "    universe_options: UniverseOptions,\n",
    ") -> TradingStrategyUniverse:\n",
    "    \"\"\"Create the trading universe.\"\"\"\n",
    "\n",
    "    start_at = pd.Timestamp(universe_options.start_at)\n",
    "    end_at = pd.Timestamp(universe_options.end_at)\n",
    "\n",
    "    print(f\"Backtesting {start_at} - {end_at}\")\n",
    "\n",
    "    chain_id = Parameters.chain_id\n",
    "\n",
    "    exchange_universe = client.fetch_exchange_universe()\n",
    "    exchange_universe = exchange_universe.limit_to_chains({Parameters.chain_id}).limit_to_slugs(SUPPORTED_DEXES)\n",
    "    print(f\"We support {exchange_universe.get_exchange_count()} DEXes\")\n",
    "\n",
    "    pairs_df = client.fetch_pair_universe().to_pandas()\n",
    "\n",
    "    liquidity_df = pd.read_parquet(liquidity_output_fname)\n",
    "    price_df = pd.read_parquet(price_output_fname)\n",
    "\n",
    "    # When reading from Parquet file, we need to deal with indexing by hand\n",
    "    liquidity_df.index = pd.DatetimeIndex(liquidity_df.timestamp)\n",
    "    price_df.index = pd.DatetimeIndex(price_df.timestamp)\n",
    "\n",
    "    print(f\"Prefilter data contains {len(liquidity_df):,} liquidity samples dn {len(price_df):,} OHLCV candles\")\n",
    "\n",
    "    # Crop price and liquidity data to our backtesting range\n",
    "    price_df = price_df.loc[(price_df.timestamp >= start_at) & (price_df.timestamp <= end_at)]\n",
    "    liquidity_df = liquidity_df.loc[(liquidity_df.timestamp >= start_at) & (liquidity_df.timestamp <= end_at)]\n",
    "\n",
    "    # Prefilter for more liquidity conditions\n",
    "    liquidity_per_pair = liquidity_df.groupby(liquidity_df.pair_id)\n",
    "    print(f\"Chain {chain_id.name} has liquidity data for {len(liquidity_per_pair.groups)}\")\n",
    "\n",
    "    passed_pair_ids = set()\n",
    "    for pair_id, pair_df in liquidity_per_pair:\n",
    "        if pair_df[\"high\"].max() > Parameters.min_liquidity:\n",
    "            passed_pair_ids.add(pair_id)\n",
    "\n",
    "    pairs_df = pairs_df.loc[pairs_df.pair_id.isin(passed_pair_ids)]\n",
    "    print(f\"After liquidity filter we have {len(pairs_df)} trading pairs\")\n",
    "\n",
    "    price_per_pair = price_df.groupby(price_df.pair_id)\n",
    "    passed_pair_ids = set()\n",
    "    for pair_id, pair_df in price_per_pair:\n",
    "        if pair_df[\"high\"].max() < Parameters.max_price and pair_df[\"low\"].min() > Parameters.min_price:\n",
    "            passed_pair_ids.add(pair_id)\n",
    "\n",
    "    pairs_df = pairs_df.loc[pairs_df.pair_id.isin(passed_pair_ids)]\n",
    "    print(f\"After broken price unit filter we have {len(pairs_df)} trading pairs\")\n",
    "\n",
    "    allowed_exchange_ids = set(exchange_universe.exchanges.keys())\n",
    "    pairs_df = pairs_df.loc[pairs_df.exchange_id.isin(allowed_exchange_ids)]\n",
    "    print(f\"After DEX filter we have {len(pairs_df)} trading pairs\")\n",
    "\n",
    "    # Do cross-section of Polygon tokens from custom data \n",
    "    pairs_df = filter_for_base_tokens(pairs_df, custom_data_token_set)\n",
    "    pairs_df = filter_for_stablecoins(pairs_df, StablecoinFilteringMode.only_volatile_pairs)\n",
    "    print(f\"After custom data ERC-20 token address cross section filter we have {len(pairs_df)} matching trading pairs\")\n",
    "\n",
    "    # Resample strategy decision candles to daily\n",
    "    daily_candles = resample_multi_pair(price_df, Parameters.candle_time_bucket)\n",
    "    daily_candles[\"timestamp\"] = daily_candles.index\n",
    "\n",
    "    print(f\"After downsampling we have {len(daily_candles)} OHLCV candles and {len(liquidity_df)} liquidity samples\")\n",
    "    candle_universe = GroupedCandleUniverse(daily_candles, forward_fill=True)  # Forward will should make sure we can always calculate RSI, other indicators\n",
    "    liquidity_universe = GroupedLiquidityUniverse(liquidity_df)\n",
    "\n",
    "    # The final trading pair universe contains metadata only for pairs that passed\n",
    "    # our filters\n",
    "    pairs_universe = PandasPairUniverse(pairs_df, exchange_universe=exchange_universe)\n",
    "    stop_loss_candle_universe = GroupedCandleUniverse(price_df)\n",
    "\n",
    "    data_universe = Universe(\n",
    "        time_bucket=Parameters.candle_time_bucket,\n",
    "        liquidity_time_bucket=Parameters.candle_time_bucket,\n",
    "        exchange_universe=exchange_universe,\n",
    "        pairs=pairs_universe,\n",
    "        candles=candle_universe,\n",
    "        liquidity=liquidity_universe,\n",
    "        chains={Parameters.chain_id}\n",
    "    )\n",
    "\n",
    "    reserve_asset = translate_token(pairs_universe.get_token(USDCE))\n",
    "\n",
    "    _strategy_universe = TradingStrategyUniverse(\n",
    "        data_universe=data_universe,\n",
    "        backtest_stop_loss_time_bucket=Parameters.stop_loss_time_bucket,\n",
    "        backtest_stop_loss_candles=stop_loss_candle_universe,\n",
    "        reserve_assets={reserve_asset},\n",
    "\n",
    "    )\n",
    "    return _strategy_universe\n",
    "\n",
    "\n",
    "strategy_universe = create_trading_universe(\n",
    "    None,\n",
    "    client,\n",
    "    notebook_execution_context,\n",
    "    UniverseOptions.from_strategy_parameters_class(Parameters, notebook_execution_context)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Indicators\n",
    "\n",
    "- We use `pandas_ta` Python package to calculate technical indicators\n",
    "- These indicators are precalculated and cached on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta\n",
    "\n",
    "from tradeexecutor.analysis.regime import Regime\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import IndicatorSet, IndicatorSource\n",
    "from tradeexecutor.strategy.parameters import StrategyParameters\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse\n",
    "from tradingstrategy.utils.groupeduniverse import resample_candles\n",
    "\n",
    "\n",
    "def rsi_safe(close_series: pd.Series, length: int):\n",
    "    # Work around tokens that appear only for few hours*\n",
    "    if len(close_series) > length:\n",
    "        return pandas_ta.rsi(close_series, length)\n",
    "    else:\n",
    "        # The token did not trade long enough we could have ever calculated RSI\n",
    "        return pd.Series(dtype=\"float64\", index=pd.DatetimeIndex([]))\n",
    "\n",
    "\n",
    "def create_indicators(\n",
    "    timestamp: datetime.datetime | None,\n",
    "    parameters: StrategyParameters,\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    "    execution_context: ExecutionContext\n",
    "):\n",
    "    indicators = IndicatorSet()\n",
    "\n",
    "    indicators.add(\n",
    "        \"rsi\",\n",
    "        rsi_safe,\n",
    "        {\"length\": parameters.rsi_length},\n",
    "        IndicatorSource.close_price,\n",
    "    )        \n",
    "    return indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trading algorithm\n",
    "\n",
    "- Describe out trading strategy as code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tradeexecutor.state.visualisation import PlotKind\n",
    "from tradeexecutor.state.trade import TradeExecution\n",
    "from tradeexecutor.strategy.pandas_trader.strategy_input import StrategyInput\n",
    "from tradeexecutor.strategy.weighting import weight_by_1_slash_n\n",
    "from tradeexecutor.strategy.alpha_model import AlphaModel\n",
    "from tradeexecutor.strategy.pandas_trader.strategy_input import IndicatorDataNotFoundWithinDataTolerance\n",
    "\n",
    "\n",
    "def decide_trades(\n",
    "    input: StrategyInput,\n",
    ") -> list[TradeExecution]:\n",
    "\n",
    "    # \n",
    "    # Decision cycle setup.\n",
    "    # Read all variables we are going to use for the decisions.\n",
    "    #\n",
    "    parameters = input.parameters\n",
    "    position_manager = input.get_position_manager()\n",
    "    state = input.state\n",
    "    timestamp = input.timestamp\n",
    "    indicators = input.indicators\n",
    "    strategy_universe = input.strategy_universe\n",
    "\n",
    "    cash = position_manager.get_current_cash()\n",
    "\n",
    "    # Another low cap problem checker.\n",
    "    # Doing a bad non-liquidity trade may break the valuation calculations.\n",
    "    total_equity = state.portfolio.get_total_equity()\n",
    "    if total_equity > 1_000_000:\n",
    "        position_valuations = \"\\n\".join([f\"{p} (token {p.pair.base.address}): {p.get_value()}\" for p in state.portfolio.open_positions.values()])\n",
    "        raise RuntimeError(f\"Portfolio total equity exceeded 1,000,000 USD. Some broken math likely happened. Total equity is {total_equity} USD.\\nOpen positions:\\n{position_valuations}\")\n",
    "        \n",
    "    #\n",
    "    # Trading logic\n",
    "    #\n",
    "    # We do some extra checks here as we are trading low quality\n",
    "    # low cap tokens which often have outright malicious data for trading.\n",
    "    #\n",
    "\n",
    "    alpha_model = AlphaModel(timestamp)\n",
    "\n",
    "    trades = []\n",
    "    for pair in strategy_universe.iterate_pairs():\n",
    "\n",
    "        # Available trading liquidity,\n",
    "        # read from the last day sample\n",
    "        tvl = indicators.get_tvl(pair=pair)\n",
    "        if tvl < parameters.min_liquidity:\n",
    "            # Not yet enough liquidity to trade\n",
    "            continue\n",
    "\n",
    "        # Check last close price\n",
    "        price = indicators.get_price(pair=pair)\n",
    "        rsi = indicators.get_indicator_value(\"rsi\", pair=pair)\n",
    "\n",
    "        # Does the trading pair have good RSI in this point of history?\n",
    "        if rsi is not None:  \n",
    "            # Interpret RSI above +50 as a positive momentum        \n",
    "            signal = rsi - 50\n",
    "            if signal > 0:\n",
    "                # Consider positive signals only, because we cannot short\n",
    "                alpha_model.set_signal(pair, signal)\n",
    "\n",
    "    # Use alpha model and construct a portfolio of four top assets\n",
    "    alpha_model.select_top_signals(parameters.max_assets)\n",
    "    alpha_model.assign_weights(weight_by_1_slash_n)\n",
    "    alpha_model.normalise_weights()\n",
    "    alpha_model.update_old_weights(state.portfolio)\n",
    "    portfolio = position_manager.get_current_portfolio()\n",
    "    portfolio_target_value = portfolio.get_total_equity() * parameters.allocation\n",
    "    alpha_model.calculate_target_positions(position_manager, portfolio_target_value)\n",
    "    trades = alpha_model.generate_rebalance_trades_and_triggers(\n",
    "        position_manager,\n",
    "        min_trade_threshold=parameters.minimum_rebalance_trade_percent * portfolio.get_total_equity(),\n",
    "    )\n",
    "\n",
    "    # Visualisations\n",
    "    #\n",
    "    if input.is_visualisation_enabled():\n",
    "        visualisation = state.visualisation\n",
    "        state.visualisation.add_calculations(timestamp, alpha_model.to_dict())  # Record alpha model thinking\n",
    "\n",
    "    return trades  # Return the list of trades we made in this cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Backtest\n",
    "\n",
    "- Run the backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from tradeexecutor.backtest.backtest_runner import run_backtest_inline\n",
    "\n",
    "result = run_backtest_inline(\n",
    "    name=parameters.id,\n",
    "    engine_version=\"0.5\",\n",
    "    decide_trades=decide_trades,\n",
    "    create_indicators=create_indicators,\n",
    "    client=client,\n",
    "    universe=strategy_universe,\n",
    "    parameters=parameters,\n",
    "    strategy_logging=False,\n",
    "    max_workers=1,\n",
    "    # We need to set this really high value, because\n",
    "    # some low cap tokens may only see 1-2 trades per year\n",
    "    # and our backtesting framework aborts if it thinks\n",
    "    # there is an issue with data quality\n",
    "    data_delay_tolerance=pd.Timedelta(days=365),\n",
    "    \n",
    "    # Uncomment to enable verbose logging\n",
    "    # log_level=logging.INFO,\n",
    ")\n",
    "\n",
    "state = result.state\n",
    "\n",
    "trade_count = len(list(state.portfolio.get_all_trades()))\n",
    "print(f\"Backtesting completed, backtested strategy made {trade_count} trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Equity curve\n",
    "\n",
    "- Equity curve shows how your strategy accrues value over time\n",
    "- A good equity curve has a stable ascending angle\n",
    "- Benchmark against MATIC buy and hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tradeexecutor.analysis.multi_asset_benchmark import get_benchmark_data\n",
    "from tradeexecutor.visual.benchmark import visualise_equity_curve_benchmark\n",
    "\n",
    "# Pulls WMATIC/USDC as the benchmark\n",
    "benchmark_indexes = get_benchmark_data(\n",
    "    strategy_universe,\n",
    "    cumulative_with_initial_cash=state.portfolio.get_initial_cash()\n",
    ")\n",
    "\n",
    "fig = visualise_equity_curve_benchmark(\n",
    "    name=state.name,\n",
    "    portfolio_statistics=state.stats.portfolio,\n",
    "    all_cash=state.portfolio.get_initial_cash(),\n",
    "    benchmark_indexes=benchmark_indexes,\n",
    "    height=800,\n",
    "    log_y=True,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Performance metrics\n",
    "\n",
    "- Display portfolio performance metrics\n",
    "- Compare against buy and hold matic using the same initial capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.multi_asset_benchmark import compare_strategy_backtest_to_multiple_assets\n",
    "\n",
    "compare_strategy_backtest_to_multiple_assets(\n",
    "    state,\n",
    "    strategy_universe,\n",
    "    display=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Trading statistics\n",
    "\n",
    "- Display summare about made trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.trade_analyser import build_trade_analysis\n",
    "\n",
    "analysis = build_trade_analysis(state.portfolio)\n",
    "summary = analysis.calculate_summary_statistics()\n",
    "display(summary.to_dataframe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
